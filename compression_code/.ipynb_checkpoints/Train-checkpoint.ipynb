{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 201024 09:57:35 config:134] Using preprocessor: <kubeflow.fairing.preprocessors.converted_notebook.ConvertNotebookPreprocessor object at 0x7f868433f0b8>\n",
      "[I 201024 09:57:35 config:136] Using builder: <kubeflow.fairing.builders.append.append.AppendBuilder object at 0x7f86829f6240>\n",
      "[I 201024 09:57:35 config:138] Using deployer: <kubeflow.fairing.deployers.job.job.Job object at 0x7f87205b90f0>\n",
      "[W 201024 09:57:35 append:50] Building image using Append builder...\n",
      "[I 201024 09:57:35 base:107] Creating docker context: /tmp/fairing_context_10leyq3h\n",
      "[I 201024 09:57:35 converted_notebook:127] Converting Train.ipynb to Train.py\n",
      "[I 201024 09:57:35 docker_creds_:234] Loading Docker credentials for repository 'khw2126/tensorflow-2.0.0-notebook-gpu:3.0.0'\n",
      "[W 201024 09:57:38 append:54] Image successfully built in 2.392741363000823s.\n",
      "[W 201024 09:57:38 append:94] Pushing image khw2126/mnist-simple:1EEFEE5B...\n",
      "[I 201024 09:57:38 docker_creds_:234] Loading Docker credentials for repository 'khw2126/mnist-simple:1EEFEE5B'\n",
      "[W 201024 09:57:38 append:81] Uploading khw2126/mnist-simple:1EEFEE5B\n",
      "[I 201024 09:57:39 docker_session_:280] Layer sha256:b975df43a955dba1874c1f589d9950bbec782e4ee058f4049f9a2da5861c5419 exists, skipping\n",
      "[I 201024 09:57:39 docker_session_:280] Layer sha256:65881bda3d6dd3c81420e22d3f921824b72ae8c07137aed41d02c640a2f87f04 exists, skipping\n",
      "[I 201024 09:57:39 docker_session_:280] Layer sha256:f23c35e66b8bb2883c25bc3daddbde267d24bf7237eb92f21a03f621daa4c70e exists, skipping\n",
      "[I 201024 09:57:39 docker_session_:280] Layer sha256:251f5509d51d9e4119d4ffb70d4820f8e2d7dc72ad15df3ebd7cd755539e40fd exists, skipping\n",
      "[I 201024 09:57:39 docker_session_:280] Layer sha256:254e6b882583cd38add312733e48658cf3ba9b9298450f97681f61f1b5eb6462 exists, skipping\n",
      "[I 201024 09:57:39 docker_session_:280] Layer sha256:06d09f7e28e650c4614bfeaa1336db8632aa02d48b9ff082d9cdf2edf4204376 exists, skipping\n",
      "[I 201024 09:57:39 docker_session_:280] Layer sha256:8810fcda1e6e2713f22a64b835ffa1ff15f49257f43dee869abef1929416d362 exists, skipping\n",
      "[I 201024 09:57:40 docker_session_:280] Layer sha256:f6490e4900cb64767e994addad4a4329cca4ccfce37a63d21249d89b63ceb478 exists, skipping\n",
      "[I 201024 09:57:40 docker_session_:280] Layer sha256:91331b4b01255f7824ba74a58ee947c21af049604414c2ee1867faf563f395e3 exists, skipping\n",
      "[I 201024 09:57:40 docker_session_:280] Layer sha256:bf5208ee1ed0b9e0d796c248a8baae8f173ddce08247fbaba85331b183037388 exists, skipping\n",
      "[I 201024 09:57:40 docker_session_:280] Layer sha256:9f0a21d58e5dce5512db6d5595c6e9c4ab014917cf0644e2d282b8f5e3f2522a exists, skipping\n",
      "[I 201024 09:57:40 docker_session_:280] Layer sha256:8ae120b4682ebc4cd5eaad3cd51ce0c879a52107b37d3f6b7b30d6e695a7837a exists, skipping\n",
      "[I 201024 09:57:40 docker_session_:280] Layer sha256:f9e7e7aaea7e58fd475e393007baf0251bad43cccaaef540a365ed1036173ae7 exists, skipping\n",
      "[I 201024 09:57:40 docker_session_:280] Layer sha256:8e829fe70a46e3ac4334823560e98b257234c23629f19f05460e21a453091e6d exists, skipping\n",
      "[I 201024 09:57:41 docker_session_:280] Layer sha256:57418a6dc9496eeb6c9324e7bdf6fd48b9e1ac25cb473bf7b71f40d44e2f1e64 exists, skipping\n",
      "[I 201024 09:57:41 docker_session_:280] Layer sha256:5b037dbf15a877e87212f212bf63494f21e31dae02d2958fdb4dc59b0a351b53 exists, skipping\n",
      "[I 201024 09:57:41 docker_session_:280] Layer sha256:35c102085707f703de2d9eaad8752d6fe1b8f02b5d2149f1d8357c9cc7fb7d0a exists, skipping\n",
      "[I 201024 09:57:41 docker_session_:280] Layer sha256:6001e1789921cf851f6fb2e5fe05be70f482fe9c2286f66892fe5a3bc404569c exists, skipping\n",
      "[I 201024 09:57:41 docker_session_:280] Layer sha256:57b3252e0bc11c18869aad84fb39d9340bf599c31258b50b1ec595209a4adfa3 exists, skipping\n",
      "[I 201024 09:57:41 docker_session_:280] Layer sha256:d701a76e3193731210c61c838de0c3d8fdc8048b613ca88a58e11dc3223221ec exists, skipping\n",
      "[I 201024 09:57:41 docker_session_:280] Layer sha256:c73ad65f0763fc76b21c650ff9a5d7f4714c30a3dc27f462aa478c829a8efed1 exists, skipping\n",
      "[I 201024 09:57:41 docker_session_:284] Layer sha256:9eafd6ca2a6bc5487d236ebe7deed941e16e6ddd8345f6e648e45044345aab2c pushed.\n",
      "[I 201024 09:57:41 docker_session_:280] Layer sha256:c1f2e9c5e641f44f8bd016d8e9060116d00632477040f66feded88297f5e1ecb exists, skipping\n",
      "[I 201024 09:57:42 docker_session_:280] Layer sha256:bbbfca4fb5f568b66f23602991f9df8c941f462465df6e40a91606dc44415110 exists, skipping\n",
      "[I 201024 09:57:42 docker_session_:280] Layer sha256:09d16a9a299ddd9465381c70e45140b627010f6616b0914b073619384af25fe4 exists, skipping\n",
      "[I 201024 09:57:42 docker_session_:280] Layer sha256:947e0f532378ce4f91ff44af563f21f5679d39a28efa2541594dd3f96730edb0 exists, skipping\n",
      "[I 201024 09:57:42 docker_session_:280] Layer sha256:e730781d596aa181dc97fc2a828635cfc0febc41d1bf64e53d8dacace49fc1ec exists, skipping\n",
      "[I 201024 09:57:42 docker_session_:280] Layer sha256:bca182449b252fcff6f220eb693713a378079a68f96ac439eb99c90894ec2371 exists, skipping\n",
      "[I 201024 09:57:42 docker_session_:280] Layer sha256:f440bbeaee4d8cb5c007d79394d2102e20848f9b91b070d18e239e1079222ba2 exists, skipping\n",
      "[I 201024 09:57:42 docker_session_:280] Layer sha256:0586a82d62e69da8dab24b635faf9c5da803ff9d208111a25b0e2253c97ec331 exists, skipping\n",
      "[I 201024 09:57:43 docker_session_:280] Layer sha256:f4f6c8e85e3e1823bb1f75e4d09a52cab9f66029e9aa725b1401c3d9e606b943 exists, skipping\n",
      "[I 201024 09:57:43 docker_session_:280] Layer sha256:74a3420b0759a0426bc7a24daf48c0f376a7e8d293c015e0681884071c3ea0e1 exists, skipping\n",
      "[I 201024 09:57:44 docker_session_:284] Layer sha256:5466e553a0e5a56a2f3d3fcf71d2887a685c6535e9ae852fbaa5f999fe98098f pushed.\n",
      "[I 201024 09:57:45 docker_session_:334] Finished upload of: khw2126/mnist-simple:1EEFEE5B\n",
      "[W 201024 09:57:45 append:99] Pushed image khw2126/mnist-simple:1EEFEE5B in 7.435856723008328s.\n",
      "[W 201024 09:57:45 job:101] The job mnist-job-144b launched.\n",
      "[W 201024 09:57:45 manager:296] Waiting for mnist-job-144b-c2cz7 to start...\n",
      "[W 201024 09:57:45 manager:296] Waiting for mnist-job-144b-c2cz7 to start...\n",
      "[W 201024 09:57:45 manager:296] Waiting for mnist-job-144b-c2cz7 to start...\n",
      "[I 201024 09:57:52 manager:302] Pod started running True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      " 2211840/11490434 [====>.........................] - ETA: 83\n",
      " 9207808/11490434 [=======================>......] - ETA: \n",
      "11493376/11490434 [==============================] - 1s 0us/step\n",
      "2020-10-24 09:57:54.564761: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2020-10-24 09:57:54.592239: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2020-10-24 09:57:54.592631: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1561] Found device 0 with properties:\n",
      "pciBusID: 0000:01:00.0 name: GeForce RTX 2070 computeCapability: 7.5\n",
      "coreClock: 1.815GHz coreCount: 36 deviceMemorySize: 7.79GiB deviceMemoryBandwidth: 417.29GiB/s\n",
      "2020-10-24 09:57:54.592871: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2020-10-24 09:57:54.592941: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcublas.so.10'; dlerror: libcublas.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2020-10-24 09:57:54.593014: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2020-10-24 09:57:54.593080: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2020-10-24 09:57:54.593132: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusolver.so.10'; dlerror: libcusolver.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2020-10-24 09:57:54.593190: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library 'libcusparse.so.10'; dlerror: libcusparse.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/extras/CUPTI/lib64:/usr/local/cuda/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2020-10-24 09:57:54.595721: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n",
      "2020-10-24 09:57:54.595742: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1598] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2020-10-24 09:57:54.595952: I tensorflow/core/platform/cpu_feature_guard.cc:143] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2020-10-24 09:57:54.602115: I tensorflow/core/platform/profile_utils/cpu_utils.cc:102] CPU Frequency: 3199980000 Hz\n",
      "2020-10-24 09:57:54.602439: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x7fbb84000b20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-10-24 09:57:54.602456: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "2020-10-24 09:57:54.603771: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1102] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2020-10-24 09:57:54.603786: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1108]\n",
      "2020-10-24 09:57:54.627439: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 376320000 exceeds 10% of free system memory.\n",
      "2020-10-24 09:57:54.773516: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 338688000 exceeds 10% of free system memory.\n",
      "2020-10-24 09:57:54.823070: W tensorflow/core/framework/cpu_allocator_impl.cc:81] Allocation of 376320000 exceeds 10% of free system memory.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #\n",
      "=================================================================\n",
      "reshape (Reshape)            (None, 28, 28, 1)         0\n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 26, 26, 12)        120\n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 12)        0\n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 2028)              0\n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 10)                20290\n",
      "=================================================================\n",
      "Total params: 20,410\n",
      "Trainable params: 20,410\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "  93/1688 [>.............................] - ETA: 4s - loss: 1.2938 - accuracy: 0.6741  \n",
      " 220/1688 [==>...........................] - ETA: 3s - loss: 0.7983 - accuracy: 0.79\n",
      " 346/1688 [=====>........................] - ETA: 3s - loss: 0.6259 - accuracy: 0.83\n",
      " 474/1688 [=======>......................] - ETA: 3s - loss: 0.5395 - accuracy: 0.85\n",
      " 588/1688 [=========>....................] - ETA: 2s - loss: 0.4836 - accuracy: 0.86\n",
      " 716/1688 [===========>..................] - ETA: 2s - loss: 0.4400 - accuracy: 0.87\n",
      " 834/1688 [=============>................] - ETA: 2s - loss: 0.4129 - accuracy: 0.88\n",
      " 961/1688 [================>.............] - ETA: 1s - loss: 0.3858 - accuracy: 0.89\n",
      "1084/1688 [==================>...........] - ETA: 1s - loss: 0.3643 - accuracy: 0.89\n",
      "1211/1688 [====================>.........] - ETA: 1s - loss: 0.3438 - accuracy: 0.90\n",
      "1335/1688 [======================>.......] - ETA: 0s - loss: 0.3278 - accuracy: 0.90\n",
      "1448/1688 [========================>.....] - ETA: 0s - loss: 0.3121 - accuracy: 0.913\n",
      "1578/1688 [===========================>..] - ETA: 0s - loss: 0.2991 - accuracy: 0.917\n",
      "1688/1688 [==============================] - 4s 3ms/step - loss: 0.2887 - accuracy: 0.9204 - val_loss: 0.1163 - val_accuracy: 0.9713\n",
      "Epoch 2/5\n",
      " 110/1688 [>.............................] - ETA: 3s - loss: 0.1320 - accuracy: 0.96\n",
      " 226/1688 [===>..........................] - ETA: 3s - loss: 0.1308 - accuracy: 0.96\n",
      " 358/1688 [=====>........................] - ETA: 3s - loss: 0.1299 - accuracy: 0.96\n",
      " 482/1688 [=======>......................] - ETA: 2s - loss: 0.1275 - accuracy: 0.96\n",
      " 604/1688 [=========>....................] - ETA: 2s - loss: 0.1256 - accuracy: 0.96\n",
      " 732/1688 [============>.................] - ETA: 2s - loss: 0.1233 - accuracy: 0.96\n",
      " 862/1688 [==============>...............] - ETA: 2s - loss: 0.1232 - accuracy: 0.96\n",
      " 990/1688 [================>.............] - ETA: 1s - loss: 0.1218 - accuracy: 0.96\n",
      "1111/1688 [==================>...........] - ETA: 1s - loss: 0.1208 - accuracy: 0.96\n",
      "1238/1688 [=====================.........] - ETA: 1s - loss: 0.1185 - accuracy: 0.96\n",
      "1367/1688 [======================>.......] - ETA: 0s - loss: 0.1160 - accuracy: 0.96\n",
      "1487/1688 [=========================>....] - ETA: 0s - loss: 0.1162 - accuracy: 0.96\n",
      "1599/1688 [===========================>..] - ETA: 0s - loss: 0.1149 - accuracy: 0.967\n",
      "1688/1688 [==============================] - 4s 3ms/step - loss: 0.1132 - accuracy: 0.9680 - val_loss: 0.0852 - val_accuracy: 0.9780\n",
      "Epoch 3/5\n",
      " 102/1688 [>.............................] - ETA: 4s - loss: 0.0770 - accuracy: 0.98\n",
      " 225/1688 [==>...........................] - ETA: 3s - loss: 0.0882 - accuracy: 0.97\n",
      " 341/1688 [=====>........................] - ETA: 3s - loss: 0.0850 - accuracy: 0.97\n",
      " 441/1688 [======>.......................] - ETA: 3s - loss: 0.0851 - accuracy: 0.97\n",
      " 553/1688 [========>.....................] - ETA: 3s - loss: 0.0862 - accuracy: 0.97\n",
      " 686/1688 [===========>..................] - ETA: 2s - loss: 0.0849 - accuracy: 0.97\n",
      " 813/1688 [=============>................] - ETA: 2s - loss: 0.0863 - accuracy: 0.97\n",
      " 916/1688 [===============>..............] - ETA: 2s - loss: 0.0862 - accuracy: 0.97\n",
      "1041/1688 [=================>............] - ETA: 1s - loss: 0.0855 - accuracy: 0.97\n",
      "1162/1688 [===================>..........] - ETA: 1s - loss: 0.0860 - accuracy: 0.97\n",
      "1279/1688 [=====================>........] - ETA: 1s - loss: 0.0850 - accuracy: 0.97\n",
      "1399/1688 [=======================>......] - ETA: 0s - loss: 0.0851 - accuracy: 0.97\n",
      "1506/1688 [=========================>....] - ETA: 0s - loss: 0.0842 - accuracy: 0.975\n",
      "1631/1688 [===========================>..] - ETA: 0s - loss: 0.0837 - accuracy: 0.975\n",
      "1688/1688 [==============================] - 5s 3ms/step - loss: 0.0832 - accuracy: 0.9759 - val_loss: 0.0698 - val_accuracy: 0.9817\n",
      "Epoch 4/5\n",
      "  88/1688 [>.............................] - ETA: 4s - loss: 0.0667 - accuracy: 0.97\n",
      " 210/1688 [==>...........................] - ETA: 3s - loss: 0.0701 - accuracy: 0.97\n",
      " 339/1688 [=====>........................] - ETA: 3s - loss: 0.0691 - accuracy: 0.98\n",
      " 472/1688 [=======>......................] - ETA: 3s - loss: 0.0671 - accuracy: 0.98\n",
      " 603/1688 [=========>....................] - ETA: 2s - loss: 0.0666 - accuracy: 0.98\n",
      " 701/1688 [===========>..................] - ETA: 2s - loss: 0.0668 - accuracy: 0.98\n",
      " 836/1688 [=============>................] - ETA: 2s - loss: 0.0676 - accuracy: 0.98\n",
      " 965/1688 [================>.............] - ETA: 1s - loss: 0.0675 - accuracy: 0.98\n",
      "1067/1688 [=================>............] - ETA: 1s - loss: 0.0674 - accuracy: 0.98\n",
      "1200/1688 [====================>.........] - ETA: 1s - loss: 0.0687 - accuracy: 0.97\n",
      "1329/1688 [======================>.......] - ETA: 0s - loss: 0.0697 - accuracy: 0.97\n",
      "1452/1688 [========================>.....] - ETA: 0s - loss: 0.0696 - accuracy: 0.97\n",
      "1560/1688 [==========================>...] - ETA: 0s - loss: 0.0694 - accuracy: 0.979\n",
      "1679/1688 [============================>.] - ETA: 0s - loss: 0.0686 - accuracy: 0.979\n",
      "1688/1688 [==============================] - 4s 3ms/step - loss: 0.0684 - accuracy: 0.9795 - val_loss: 0.0684 - val_accuracy: 0.9820\n",
      "Epoch 5/5\n",
      "  90/1688 [>.............................] - ETA: 4s - loss: 0.0458 - accuracy: 0.98\n",
      " 217/1688 [==>...........................] - ETA: 3s - loss: 0.0561 - accuracy: 0.98\n",
      " 342/1688 [=====>........................] - ETA: 3s - loss: 0.0570 - accuracy: 0.98\n",
      " 465/1688 [=======>......................] - ETA: 3s - loss: 0.0587 - accuracy: 0.98\n",
      " 577/1688 [=========>....................] - ETA: 2s - loss: 0.0592 - accuracy: 0.98\n",
      " 696/1688 [===========>..................] - ETA: 2s - loss: 0.0615 - accuracy: 0.98\n",
      " 812/1688 [=============>................] - ETA: 2s - loss: 0.0600 - accuracy: 0.98\n",
      " 929/1688 [===============>..............] - ETA: 1s - loss: 0.0603 - accuracy: 0.98\n",
      "1055/1688 [=================>............] - ETA: 1s - loss: 0.0600 - accuracy: 0.98\n",
      "1179/1688 [===================>..........] - ETA: 1s - loss: 0.0600 - accuracy: 0.98\n",
      "1293/1688 [=====================>........] - ETA: 1s - loss: 0.0588 - accuracy: 0.98\n",
      "1423/1688 [=======================>......] - ETA: 0s - loss: 0.0584 - accuracy: 0.98\n",
      "1531/1688 [==========================>...] - ETA: 0s - loss: 0.0591 - accuracy: 0.982\n",
      "1654/1688 [============================>.] - ETA: 0s - loss: 0.0587 - accuracy: 0.983\n",
      "1688/1688 [==============================] - 4s 3ms/step - loss: 0.0587 - accuracy: 0.9830 - val_loss: 0.0617 - val_accuracy: 0.9827\n",
      "79/79 [==============================] - 0s 2ms/step - loss: 0.0615 - accuracy: 0.9809\n",
      "test loss, test acc: [0.061479631811380386, 0.98089998960495]\n",
      "Base model accuracy :  0.98089998960495\n",
      "Base model size:  78029\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "#import tensorflow_model_optimization as tfmot\n",
    "import argparse\n",
    "from tensorflow.python.keras.callbacks import Callback\n",
    "from tensorflow.python.lib.io import file_io\n",
    "import json\n",
    "\n",
    "\n",
    "# 모델 사이즈를 측정하기 위한 함수\n",
    "def get_gzipped_model_size(file):\n",
    "  # Returns size of gzipped model, in bytes.\n",
    "    import os\n",
    "    import zipfile\n",
    "\n",
    "    _, zipped_file = tempfile.mkstemp('.zip')\n",
    "    with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "        f.write(file)\n",
    "\n",
    "    return os.path.getsize(zipped_file)\n",
    "\n",
    "class Mnist(object):\n",
    "    def train(self):\n",
    "\n",
    "        parser = argparse.ArgumentParser()\n",
    "        parser.add_argument('--learning_rate', required=False, type=float, default=0.001)\n",
    "        parser.add_argument('--dropout_rate', required=False, type=float, default=0.3)  \n",
    "        parser.add_argument('--model_path', required=False, default='/result',type = str)  #/saved_model\n",
    "        parser.add_argument('--model_version', required=False, default='/base_model.h5',type = str)#test2/Base_model.h5\n",
    "        args = parser.parse_args()\n",
    "\n",
    "\n",
    "\n",
    "        # Load MNIST dataset\n",
    "        mnist = tf.keras.datasets.mnist\n",
    "        (train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "        # Normalize the input image so that each pixel value is between 0 to 1.\n",
    "        train_images = train_images / 255.0\n",
    "        test_images = test_images / 255.0\n",
    "        # Define the model architecture\n",
    "        model = tf.keras.Sequential([\n",
    "          tf.keras.layers.InputLayer(input_shape=(28, 28)),\n",
    "          tf.keras.layers.Reshape(target_shape=(28, 28, 1)),\n",
    "          tf.keras.layers.Conv2D(filters=12, kernel_size=(3, 3), activation='relu'),\n",
    "          tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "          tf.keras.layers.Flatten(),\n",
    "          tf.keras.layers.Dense(10)\n",
    "        ])\n",
    "        \n",
    "        model.summary()\n",
    "\n",
    "        # Train the digit classification model\n",
    "        model.compile(optimizer='adam',\n",
    "                      loss=tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "                          from_logits=True),\n",
    "                      metrics=['accuracy'])\n",
    "        model.fit(\n",
    "          train_images,\n",
    "          train_labels,\n",
    "          epochs=5,\n",
    "          validation_split=0.1,\n",
    "        )\n",
    "        #model.fit(x_train, y_train, epochs=5,callbacks=[KatibMetricLog()])\n",
    "\n",
    "        \n",
    "        results = model.evaluate(test_images, test_labels, batch_size=128)\n",
    "        print('test loss, test acc:', results)\n",
    "        \n",
    "        _, model_accuracy = model.evaluate(test_images, test_labels, verbose=0)\n",
    "        print(\"Base model accuracy : \", model_accuracy)\n",
    "        \n",
    "        \n",
    "        loss = results[0]\n",
    "        accuracy = results[1]\n",
    "        metrics = {\n",
    "            'metrics': [{\n",
    "                'name': 'accuracy',\n",
    "                'numberValue': float(accuracy),\n",
    "                'format': \"PERCENTAGE\",\n",
    "            }, {\n",
    "                'name': 'loss',\n",
    "                'numberValue': float(loss),\n",
    "                'format': \"RAW\",\n",
    "            }]\n",
    "        }\n",
    "        \n",
    "        with file_io.FileIO('/mlpipeline-metrics.json', 'w') as f:\n",
    "            json.dump(metrics, f)\n",
    "   \n",
    "    \n",
    "        #path = args.saved_model_dir + \"/\" + args.model_version\n",
    "        #export_path = os.path.join(args.model_path, str(args.model_version))#, 'Base_model.h5'\n",
    "        #print(\"model path: \",export_path)\n",
    "        #print (os.getcwd())\n",
    "#         print(args.model_path)\n",
    "#         print(os.listdir(args.model_path))\n",
    "#         print(os.path.isdir(args.model_path))\n",
    "        #_, keras_file = tempfile.mkstemp(suffix=args.model_version, dir=args.model_path)\n",
    "        tf.keras.models.save_model(model, args.model_path+args.model_version, include_optimizer=False) #os.getcwd()+'/'+args.model_version.split('/')[1]\n",
    "        #model.save(export_path, include_optimizer=False)\n",
    "        #print(\"model path has files: \", os.listdir(export_path))\n",
    "        print(\"Base model size: \",get_gzipped_model_size(args.model_path+args.model_version))\n",
    "\n",
    "\n",
    "def fairing_run():\n",
    "    CONTAINER_REGISTRY = 'khw2126'\n",
    "\n",
    "    namespace = 'admin'\n",
    "    job_name = f'mnist-job-{uuid.uuid4().hex[:4]}'\n",
    "\n",
    "\n",
    "    fairing.config.set_builder('append', registry=CONTAINER_REGISTRY, image_name=\"mnist-simple\",base_image=\"khw2126/tensorflow-2.0.0-notebook-gpu:3.0.0\")\n",
    "\n",
    "    #fairing.config.set_deployer('job', namespace=namespace, job_name=job_name, cleanup=False, stream_log=True)\n",
    "    \n",
    "    fairing.config.set_deployer('job', namespace=namespace, job_name=job_name, cleanup=False, stream_log=True,\n",
    "                                pod_spec_mutators=[\n",
    "                                    k8s_utils.mounting_pvc(pvc_name=\"workspace-hufsice\", \n",
    "                                                           pvc_mount_path=\"/result\")])\n",
    "\n",
    "    fairing.config.run()\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    if os.getenv('FAIRING_RUNTIME', None) is None:\n",
    "        import uuid\n",
    "        from kubeflow import fairing\n",
    "        from kubeflow.fairing.kubernetes import utils as k8s_utils\n",
    "        fairing_run()\n",
    "    else:\n",
    "        remote_train = Mnist()\n",
    "        remote_train.train()\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
