{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow import keras\n",
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "import argparse\n",
    "from tensorflow.python.keras.callbacks import Callback\n",
    "from tensorflow.python.lib.io import file_io\n",
    "import json\n",
    "import zipfile\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--learning_rate', required=False, type=float, default=0.001)\n",
    "parser.add_argument('--dropout_rate', required=False, type=float, default=0.3)  \n",
    "parser.add_argument('--model_path', required=False, default='/result/saved_model',type = str)  \n",
    "parser.add_argument('--model_version', required=False, default='1',type = str)\n",
    "parser.add_argument('--model_version3', required=False, default='1',type = str)\n",
    "parser.add_argument('--model_version8', required=False, default='1',type = str)\n",
    "args = parser.parse_args()   \n",
    "\n",
    "\n",
    "# 모델 사이즈를 측정하기 위한 함수\n",
    "def get_gzipped_model_size(file):\n",
    "    _, zipped_file = tempfile.mkstemp('.zip')#,dir=args.model_path\n",
    "    with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "        f.write(file)\n",
    "        \n",
    "    return os.path.getsize(zipped_file)\n",
    "\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "train_images = train_images.astype(np.float32) / 255.0\n",
    "test_images = test_images.astype(np.float32) / 255.0\n",
    "\n",
    "# model load(base model)\n",
    "model = keras.models.load_model(args.model_path+args.model_version)\n",
    "\n",
    "quantize_model = tfmot.quantization.keras.quantize_model\n",
    "# q_aware stands for for quantization aware.\n",
    "q_aware_model = quantize_model(model)\n",
    "\n",
    "# `quantize_model` requires a recompile.\n",
    "q_aware_model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "\n",
    "q_aware_model.summary()\n",
    "\n",
    "#train_images_subset = train_images[0:1000] # out of 60000\n",
    "#train_labels_subset = train_labels[0:1000]\n",
    "\n",
    "q_aware_model.fit(train_images, train_labels,batch_size=500, epochs=1, validation_split=0.1)\n",
    "\n",
    "results = q_aware_model.evaluate(test_images,test_labels, batch_size=500)\n",
    "print('test loss, test acc:', results)\n",
    "loss = results[0]\n",
    "accuracy = results[1]\n",
    "metrics = {\n",
    "    'metrics': [{\n",
    "        'name': 'accuracy',\n",
    "        'numberValue': float(accuracy),\n",
    "        'format': \"PERCENTAGE\",\n",
    "    }, {\n",
    "        'name': 'loss',\n",
    "        'numberValue': float(loss),\n",
    "        'format': \"RAW\",\n",
    "    }]\n",
    "}\n",
    "\n",
    "with file_io.FileIO('/mlpipeline-metrics.json', 'w') as f:\n",
    "    json.dump(metrics, f)\n",
    "\n",
    "_, q_aware_model_accuracy = q_aware_model.evaluate(test_images, test_labels, verbose=0)\n",
    "print(\"Quant test accuracy: \", q_aware_model_accuracy)\n",
    "\n",
    "tf.keras.models.save_model(q_aware_model, args.model_path+args.model_version3, include_optimizer=False)\n",
    "print(\"Quant model size: \",get_gzipped_model_size(args.model_path+args.model_version3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
