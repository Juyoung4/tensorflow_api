{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tempfile\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow import keras\n",
    "import tensorflow_model_optimization as tfmot\n",
    "\n",
    "import argparse\n",
    "from tensorflow.python.keras.callbacks import Callback\n",
    "from tensorflow.python.lib.io import file_io\n",
    "import json\n",
    "import zipfile\n",
    "import pathlib\n",
    "\n",
    "\n",
    "################### args ##########################################\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--learning_rate', required=False, type=float, default=0.001)\n",
    "parser.add_argument('--dropout_rate', required=False, type=float, default=0.3)  \n",
    "parser.add_argument('--model_path', required=False, default='/result/saved_model',type = str)  \n",
    "parser.add_argument('--model_version', required=False, default='1',type = str)\n",
    "parser.add_argument('--model_version2', required=False, default='1',type = str)\n",
    "args = parser.parse_args()\n",
    "\n",
    "\n",
    "################### tflite functions ###########################\n",
    "def devaluate_model(interpreter):\n",
    "    input_index = interpreter.get_input_details()[0][\"index\"]\n",
    "    output_index = interpreter.get_output_details()[0][\"index\"]\n",
    "\n",
    "    # Run predictions on every image in the \"test\" dataset.\n",
    "    prediction_digits = []\n",
    "    for test_image in test_images:\n",
    "    # Pre-processing: add batch dimension and convert to float32 to match with\n",
    "    # the model's input data format.\n",
    "        test_image = np.expand_dims(test_image, axis=0).astype(np.float32)\n",
    "        interpreter.set_tensor(input_index, test_image)\n",
    "\n",
    "    # Run inference.\n",
    "        interpreter.invoke()\n",
    "\n",
    "        # Post-processing: remove batch dimension and find the digit with highest\n",
    "        # probability.\n",
    "        output = interpreter.tensor(output_index)\n",
    "        digit = np.argmax(output()[0])\n",
    "        prediction_digits.append(digit)\n",
    "\n",
    "  # Compare prediction results with ground truth labels to calculate accuracy.\n",
    "    accurate_count = 0\n",
    "    for index in range(len(prediction_digits)):\n",
    "        if prediction_digits[index] == test_labels[index]:\n",
    "            accurate_count += 1\n",
    "    accuracy = accurate_count * 1.0 / len(prediction_digits)\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "def get_gzipped_model_size(file):\n",
    "  # Returns size of gzipped model, in bytes.\n",
    "    import os\n",
    "    import zipfile\n",
    "\n",
    "    _, zipped_file = tempfile.mkstemp('.zip')\n",
    "    with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "        f.write(file)\n",
    "\n",
    "    return os.path.getsize(zipped_file)\n",
    "###########################################################################\n",
    "\n",
    "# model load(base model)\n",
    "model = keras.models.load_model(args.model_path+args.model_version)\n",
    "\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "dynamic_post_quan_tflite_model = converter.convert()\n",
    "\n",
    "interpreter_dynamic_post_q = tf.lite.Interpreter(model_content=dynamic_post_quan_tflite_model)\n",
    "input_type = interpreter_dynamic_post_q.get_input_details()[0]['dtype']\n",
    "print('input: ', input_type)\n",
    "output_type = interpreter_dynamic_post_q.get_output_details()[0]['dtype']\n",
    "print('output: ', output_type)\n",
    "\n",
    "dynamic_post_quan_tflite_file = pathlib.Path(args.model_path+args.model_version2)\n",
    "dynamic_post_quan_tflite_file.write_bytes(dynamic_post_quan_tflite_model)\n",
    "\n",
    "interpreter_dynamic_post_q.allocate_tensors()\n",
    "dynamic_post_q_accuracy = devaluate_model(interpreter_dynamic_post_q)\n",
    "\n",
    "print('Dynamic Post-Quant test accuracy:', dynamic_post_q_accuracy)\n",
    "print('Dynamic Post-Quant size:', get_gzipped_model_size(dynamic_post_quan_tflite_file))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
