{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IMDB.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPFc4auwyPqPJF6kw1EyiTQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Juyoung4/tensorflow_api/blob/master/IMDB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQAVWC5BSJLU",
        "colab_type": "text"
      },
      "source": [
        "# IMDB_LSTM 모델 경량화"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8lfPlBcmyaJ",
        "colab_type": "code",
        "outputId": "9a3b3e7f-a482-43a3-ddd5-ab1ae589525c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "!pip install tensorflow-model-optimization"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-model-optimization\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/09/7e/e94aa029999ec30951e8129fa992fecbbaffda66eba97c65d5a83f8ea96d/tensorflow_model_optimization-0.3.0-py2.py3-none-any.whl (165kB)\n",
            "\u001b[K     |████████████████████████████████| 174kB 15.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: six~=1.10 in /usr/local/lib/python3.6/dist-packages (from tensorflow-model-optimization) (1.12.0)\n",
            "Requirement already satisfied: numpy~=1.14 in /usr/local/lib/python3.6/dist-packages (from tensorflow-model-optimization) (1.18.5)\n",
            "Collecting dm-tree~=0.1.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/16/48/10fb721334810081b7e6eebeba0d12e12126c76993e8c243062d2f56a89f/dm_tree-0.1.5-cp36-cp36m-manylinux1_x86_64.whl (294kB)\n",
            "\u001b[K     |████████████████████████████████| 296kB 10.5MB/s \n",
            "\u001b[?25hInstalling collected packages: dm-tree, tensorflow-model-optimization\n",
            "Successfully installed dm-tree-0.1.5 tensorflow-model-optimization-0.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yu63f-m5wXRK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function #python2 에서 3문법 사용\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tempfile\n",
        "import os\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow_model_optimization as tfmot"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HIJW_XjSfpd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow.keras as keras\n",
        "import tensorflow.keras.backend as K\n",
        "import tensorflow.keras.preprocessing.sequence as sequence\n",
        "from tensorflow_model_optimization.python.core.sparsity.keras import prune\n",
        "from tensorflow_model_optimization.python.core.sparsity.keras import pruning_callbacks\n",
        "from tensorflow_model_optimization.python.core.sparsity.keras import pruning_schedule\n",
        "from tensorflow_model_optimization.python.core.sparsity.keras import pruning_wrapper"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCDXuboiSphL",
        "colab_type": "code",
        "outputId": "56984066-7fbe-45d4-b0a0-1938447e9454",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njQdgqidwg5C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "maxlen = 100  # cut texts after this number of words\n",
        "batch_size = 32 #1 step에서 사용되는 데이터 수"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oET9bZGS2xY",
        "colab_type": "text"
      },
      "source": [
        "## 1. IMDB 데이터셋 가져오기\n",
        "IMDB는 kearas에서 제공해주는 영화 리뷰 데이터이며 긍정, 부정 감정을 분류한다.\n",
        "\n",
        "영화 리뷰는 X_train에, 감성 정보는 y_train에 저장된다.(긍정리뷰:1, 부정리뷰:0)\n",
        "\n",
        "num_words 인자에 20000이라고 지정하여 많이 사용하는 순 위 20000번째 까지의 단어만을 데이터셋으로 사용한다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5v-a5M0Zr99O",
        "colab_type": "code",
        "outputId": "8eb307ae-c123-4d98-a387-55f226a81126",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "imdb = keras.datasets.imdb\n",
        "\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=20000)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpVqqSDlsd9c",
        "colab_type": "code",
        "outputId": "e693b769-a9fa-4795-d8b7-33569ebfa8c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "print('훈련용 리뷰 개수 : {}'.format(len(x_train)))\n",
        "print('테스트용 리뷰 개수 : {}'.format(len(x_test)))\n",
        "num_classes = max(y_train) + 1\n",
        "print('카테고리 : {}'.format(num_classes))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "훈련용 리뷰 개수 : 25000\n",
            "테스트용 리뷰 개수 : 25000\n",
            "카테고리 : 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OGuoN3nhRv0R",
        "colab_type": "code",
        "outputId": "98a646e5-5d5a-4a7f-e95c-8b017015a196",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "print(\"Pad sequences (samples x time)\")\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(\"x_test shape:\", x_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pad sequences (samples x time)\n",
            "x_train shape: (25000, 100)\n",
            "x_test shape: (25000, 100)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XR1M4OGrSx9V",
        "colab_type": "code",
        "outputId": "b04ce4d1-f90a-4cb2-dac3-07a1e97552f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "print(x_train[0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[ 1415    33     6    22    12   215    28    77    52     5    14   407\n",
            "    16    82 10311     8     4   107   117  5952    15   256     4     2\n",
            "     7  3766     5   723    36    71    43   530   476    26   400   317\n",
            "    46     7     4 12118  1029    13   104    88     4   381    15   297\n",
            "    98    32  2071    56    26   141     6   194  7486    18     4   226\n",
            "    22    21   134   476    26   480     5   144    30  5535    18    51\n",
            "    36    28   224    92    25   104     4   226    65    16    38  1334\n",
            "    88    12    16   283     5    16  4472   113   103    32    15    16\n",
            "  5345    19   178    32]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DGKxZ0YovlBT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def print_model_sparsity(pruned_model):\n",
        "  \"\"\"Prints sparsity for the pruned layers in the model.\n",
        "  Model Sparsity Summary\n",
        "  --\n",
        "  prune_lstm_1: (kernel, 0.5), (recurrent_kernel, 0.6)\n",
        "  prune_dense_1: (kernel, 0.5)\n",
        "  Args:\n",
        "    pruned_model: keras model to summarize.\n",
        "  Returns:\n",
        "    None\n",
        "  \"\"\"\n",
        "  \n",
        "  def _get_sparsity(weights):\n",
        "    return 1.0 - np.count_nonzero(weights) / float(weights.size)\n",
        "\n",
        "  print(\"Model Sparsity Summary ({})\".format(pruned_model.name))\n",
        "  print(\"--\")\n",
        "  for layer in pruned_model.layers:\n",
        "    if isinstance(layer, pruning_wrapper.PruneLowMagnitude):\n",
        "      prunable_weights = layer.layer.get_prunable_weights()\n",
        "      if prunable_weights:\n",
        "        print(\"{}: {}\".format(\n",
        "            layer.name, \", \".join([\n",
        "                \"({}, {})\".format(weight.name,\n",
        "                                  str(_get_sparsity(K.get_value(weight))))\n",
        "                for weight in prunable_weights\n",
        "            ])))\n",
        "  print(\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8tSq3JU7TGz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#모델 생성\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Embedding(20000, 128, input_length=maxlen),\n",
        "  tf.keras.layers.LSTM(128),\n",
        "  tf.keras.layers.Dropout(0.5),\n",
        "  tf.keras.layers.Dense(1),\n",
        "  tf.keras.layers.Activation(activation='sigmoid')\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hegb4q0y8zoF",
        "colab_type": "code",
        "outputId": "ab129ee9-abdd-4ea3-9917-b12e76a39fab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, 100, 128)          2560000   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 128)               131584    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 129       \n",
            "_________________________________________________________________\n",
            "activation (Activation)      (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 2,691,713\n",
            "Trainable params: 2,691,713\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FNrkKu0xvae",
        "colab_type": "code",
        "outputId": "7e7fe2b1-77eb-45ae-faec-e5ba083c50cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "model.compile(loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "              optimizer=\"adam\",\n",
        "              metrics=[\"accuracy\"])\n",
        "print_model_sparsity(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Sparsity Summary (sequential)\n",
            "--\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CSKHk-NxyqQ",
        "colab_type": "code",
        "outputId": "39e1aa8b-d136-482e-f7c1-b69ab58f677b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "\n",
        "print(\"Train...\")\n",
        "model.fit(x_train, y_train, batch_size=batch_size, epochs=3,\n",
        "          callbacks=[pruning_callbacks.UpdatePruningStep()],\n",
        "          validation_data=(x_test, y_test))\n",
        "score, acc = model.evaluate(x_test, y_test,\n",
        "                            batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train...\n",
            "Epoch 1/3\n",
            "782/782 [==============================] - 28s 36ms/step - loss: 0.4131 - accuracy: 0.8127 - val_loss: 0.3586 - val_accuracy: 0.8464\n",
            "Epoch 2/3\n",
            "782/782 [==============================] - 27s 35ms/step - loss: 0.2367 - accuracy: 0.9083 - val_loss: 0.3524 - val_accuracy: 0.8456\n",
            "Epoch 3/3\n",
            "782/782 [==============================] - 26s 34ms/step - loss: 0.1492 - accuracy: 0.9461 - val_loss: 0.5261 - val_accuracy: 0.8350\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.5261 - accuracy: 0.8350\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_A_DACcPRA_",
        "colab_type": "code",
        "outputId": "472fe63e-e0b3-4a06-f2cd-08d50b79c9bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "base_score,  baseline_model_accuracy = model.evaluate(x_test, y_test,\n",
        "                            batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 3s 4ms/step - loss: 0.5261 - accuracy: 0.8350\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQjAJZ6Zyfku",
        "colab_type": "code",
        "outputId": "e44654be-c123-4888-fcef-1d92e9adabd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "print_model_sparsity(model)\n",
        "print(\"Baseline test score:\", base_score)\n",
        "print(\"Baseline test accuracy:\",  baseline_model_accuracy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Sparsity Summary (sequential)\n",
            "--\n",
            "\n",
            "\n",
            "Baseline test score: 0.5261352062225342\n",
            "Baseline test accuracy: 0.8349999785423279\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQfqKUvryJxl",
        "colab_type": "code",
        "outputId": "920c1ce0-9eae-4f87-c27e-918a0191682d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "_, keras_file = tempfile.mkstemp('.h5')\n",
        "tf.keras.models.save_model(model, keras_file, include_optimizer=False)\n",
        "print('Saved baseline model to:', keras_file)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved baseline model to: /tmp/tmpvv87jesg.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VOIQO8ZfxOwj",
        "colab_type": "text"
      },
      "source": [
        "## 2. baseline model with only pruning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_3MtLkU0-w4m",
        "colab_type": "code",
        "outputId": "ee7fd451-44e6-42cf-bd10-147ed1b7cd01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        }
      },
      "source": [
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
        "\n",
        "# Compute end step to finish pruning after 2 epochs.\n",
        "batch_size = 32\n",
        "epochs = 3\n",
        "validation_split = 0.1 # 10% of training set will be used for validation set. \n",
        "\n",
        "\n",
        "# Define model for pruning.\n",
        "pruning_params = {\n",
        "      'pruning_schedule': tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.30,\n",
        "                                                               final_sparsity=0.70,\n",
        "                                                               begin_step=1000,\n",
        "                                                               end_step=3000)\n",
        "}\n",
        "\n",
        "model_for_pruning = prune_low_magnitude(model, **pruning_params)\n",
        "\n",
        "# `prune_low_magnitude` requires a recompile.\n",
        "model_for_pruning.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_for_pruning.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_model_optimization/python/core/sparsity/keras/pruning_wrapper.py:199: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `layer.add_weight` method instead.\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "prune_low_magnitude_embeddin (None, 100, 128)          5120002   \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_lstm (Pr (None, 128)               262659    \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_dropout  (None, 128)               1         \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_dense (P (None, 1)                 259       \n",
            "_________________________________________________________________\n",
            "prune_low_magnitude_activati (None, 1)                 1         \n",
            "=================================================================\n",
            "Total params: 5,382,922\n",
            "Trainable params: 2,691,713\n",
            "Non-trainable params: 2,691,209\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "saXnl-3D_tse",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logdir = tempfile.mkdtemp()\n",
        "\n",
        "callbacks = [\n",
        "  tfmot.sparsity.keras.UpdatePruningStep(),\n",
        "  tfmot.sparsity.keras.PruningSummaries(log_dir=logdir),\n",
        "]\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sj70Lxtgv3js",
        "colab_type": "code",
        "outputId": "e612d600-d9c0-4cc5-a633-75baced17b77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "print(\"Train...\")\n",
        "model_for_pruning.fit(x_train, y_train, batch_size=batch_size, epochs=3,\n",
        "          callbacks=[pruning_callbacks.UpdatePruningStep()],\n",
        "          validation_data=(x_test, y_test))\n",
        "pruned_score, pruned_acc = model_for_pruning.evaluate(x_test, y_test,\n",
        "                            batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train...\n",
            "Epoch 1/3\n",
            "782/782 [==============================] - 41s 52ms/step - loss: 0.1083 - accuracy: 0.9627 - val_loss: 0.4778 - val_accuracy: 0.8266\n",
            "Epoch 2/3\n",
            "782/782 [==============================] - 41s 53ms/step - loss: 0.0605 - accuracy: 0.9802 - val_loss: 0.5600 - val_accuracy: 0.8264\n",
            "Epoch 3/3\n",
            "782/782 [==============================] - 41s 53ms/step - loss: 0.0405 - accuracy: 0.9879 - val_loss: 0.6889 - val_accuracy: 0.8272\n",
            "782/782 [==============================] - 9s 12ms/step - loss: 0.6889 - accuracy: 0.8272\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "faNTO_Xmv6da",
        "colab_type": "code",
        "outputId": "3e6474f7-d3cc-4296-b6ac-81632958abaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "print_model_sparsity(model_for_pruning)\n",
        "print(\"Pruned test score:\", pruned_score)\n",
        "print(\"Pruned test accuracy:\", pruned_acc)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Sparsity Summary (sequential)\n",
            "--\n",
            "prune_low_magnitude_embedding: (embedding/embeddings:0, 0.68285)\n",
            "prune_low_magnitude_lstm: (lstm/lstm_cell/kernel:0, 0.6828460693359375), (lstm/lstm_cell/recurrent_kernel:0, 0.6828460693359375)\n",
            "prune_low_magnitude_dense: (dense/kernel:0, 0.6796875)\n",
            "\n",
            "\n",
            "Pruned test score: 0.6888934373855591\n",
            "Pruned test accuracy: 0.8271600008010864\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pglOZbczBlw",
        "colab_type": "code",
        "outputId": "f9c3184b-56a7-44bd-be51-08f33957afc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model_for_export = tfmot.sparsity.keras.strip_pruning(model_for_pruning)\n",
        "\n",
        "_, pruned_keras_file = tempfile.mkstemp('.h5')\n",
        "tf.keras.models.save_model(model_for_export, pruned_keras_file, include_optimizer=False)\n",
        "print('Saved pruned Keras model to:', pruned_keras_file)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved pruned Keras model to: /tmp/tmp7o5wfm_h.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FcofExFVtG-",
        "colab_type": "text"
      },
      "source": [
        "## 3-1. baseline model with only quantizing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDL_T1GHecvU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q tensorflow-model-optimization"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOe6P0MJV0jp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow_model_optimization as tfmot\n",
        "\n",
        "quantize_annotate_layer = tfmot.quantization.keras.quantize_annotate_layer\n",
        "quantize_apply = tfmot.quantization.keras.quantize_apply\n",
        "\n",
        "\n",
        "\n",
        "q_annotate_model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Embedding(20000, 128, input_length=maxlen),\n",
        "  tf.keras.layers.LSTM(128),\n",
        "  quantize_annotate_layer(tf.keras.layers.Dropout(0.5)),\n",
        "  quantize_annotate_layer(tf.keras.layers.Dense(1)),\n",
        "  tf.keras.layers.Activation(activation='sigmoid')\n",
        "])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agLB9-U_nqh3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "q_aware_model = quantize_apply(q_annotate_model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4ncIX3OgM0i",
        "colab_type": "code",
        "outputId": "be9ebe85-d38e-4556-ccca-9cf96f4f3ef7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        }
      },
      "source": [
        "q_aware_model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_7 (Embedding)      (None, 100, 128)          2560000   \n",
            "_________________________________________________________________\n",
            "lstm_6 (LSTM)                (None, 128)               131584    \n",
            "_________________________________________________________________\n",
            "quant_dropout_6 (QuantizeWra (None, 128)               1         \n",
            "_________________________________________________________________\n",
            "quant_dense_6 (QuantizeWrapp (None, 1)                 134       \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 2,691,719\n",
            "Trainable params: 2,691,713\n",
            "Non-trainable params: 6\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZqVhuRpZsm7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "q_aware_model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ta0FTH0uapab",
        "colab_type": "code",
        "outputId": "09cca5c6-79ab-49eb-a9df-1ffa5dd20140",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "print(\"Train...\")\n",
        "q_aware_model.fit(x_train, y_train,\n",
        "                  batch_size=batch_size, epochs=3, validation_split=0.1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train...\n",
            "Epoch 1/3\n",
            "704/704 [==============================] - 23s 33ms/step - loss: 0.4271 - accuracy: 0.7982 - val_loss: 0.3595 - val_accuracy: 0.8424\n",
            "Epoch 2/3\n",
            "704/704 [==============================] - 23s 32ms/step - loss: 0.2343 - accuracy: 0.9078 - val_loss: 0.3698 - val_accuracy: 0.8452\n",
            "Epoch 3/3\n",
            "704/704 [==============================] - 22s 32ms/step - loss: 0.1417 - accuracy: 0.9495 - val_loss: 0.4304 - val_accuracy: 0.8464\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2175c31da0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fS2asLIbQGUe",
        "colab_type": "code",
        "outputId": "eb0e4fe7-90f7-431e-afef-fc00921c1944",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "q_aware_model_score, q_aware_model_accuracy = q_aware_model.evaluate(x_test, y_test,\n",
        "                            batch_size=batch_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 4s 5ms/step - loss: 0.4463 - accuracy: 0.8362\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSYJXxyXb-yA",
        "colab_type": "code",
        "outputId": "374465cc-1cc8-4d39-db03-d3c3560772d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "print_model_sparsity(q_aware_model)\n",
        "print(\"Quant test score:\", q_aware_model_score)\n",
        "print(\"Qaunt test accuracy:\",q_aware_model_accuracy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model Sparsity Summary (sequential_5)\n",
            "--\n",
            "\n",
            "\n",
            "Quant test score: 0.4463203549385071\n",
            "Qaunt test accuracy: 0.8361999988555908\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnQQ1zlSd3dx",
        "colab_type": "code",
        "outputId": "1fabbc0a-42ea-482f-dd25-b83a2d4d05e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "_, quantized_keras_file = tempfile.mkstemp('.h5')\n",
        "tf.keras.models.save_model(q_aware_model, quantized_keras_file, include_optimizer=False)\n",
        "print('Saved quantized Keras model to:', quantized_keras_file)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved quantized Keras model to: /tmp/tmpmqa6zj73.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "InE2RqASd9oP",
        "colab_type": "code",
        "outputId": "789d3781-05e4-4029-e488-45f7acb4c759",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(\"Size of gzipped pruned Keras model: %.2f bytes\" % (get_gzipped_model_size(quantized_keras_file)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of gzipped pruned Keras model: 9967802.00 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k-VjgD33N3xD",
        "colab_type": "text"
      },
      "source": [
        "## 3-2. baseline model with post-quatizing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gQOxJoGjVF8a",
        "colab_type": "code",
        "outputId": "f06b90e0-aea4-4bcc-fcb7-6d706033a0f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        }
      },
      "source": [
        "!pip install tf-nightly"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tf-nightly in /usr/local/lib/python3.6/dist-packages (2.3.0.dev20200611)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.6.3)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (3.10.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.12.1)\n",
            "Requirement already satisfied: tb-nightly<2.4.0a0,>=2.3.0a0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (2.3.0a20200611)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.4.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.29.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.18.5)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.1.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.9.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (3.2.1)\n",
            "Requirement already satisfied: tf-estimator-nightly in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (2.3.0.dev2020061101)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.2.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (0.34.2)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (2.10.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tf-nightly) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.9.2->tf-nightly) (47.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (1.6.0.post3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (0.4.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (3.2.2)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (2.23.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (1.7.2)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (1.6.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (3.0.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (0.2.8)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (3.1.1)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (4.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (3.1.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tb-nightly<2.4.0a0,>=2.3.0a0->tf-nightly) (0.4.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7lu0kI-ZZuL",
        "colab_type": "text"
      },
      "source": [
        "### TensorFlow Lite 모델로 변환\n",
        "\n",
        " 훈련 된 모델을 TensorFlow Lite 모델로 변환 할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AYElswFN5Si",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "converter.experimental_new_quantizer = True\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "post_quan_tflite_model = converter.convert()\n",
        "\n",
        "_,post_quan_tflite_file = tempfile.mkstemp('.tflite')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUXNtTkeN9li",
        "colab_type": "code",
        "outputId": "757bc348-2f4d-4ee5-a1eb-9df0bca315a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Saved post-quantized TFLite model to:',post_quan_tflite_file)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved post-quantized TFLite model to: /tmp/tmpj97h_l1f.tflite\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnhZ_u8_YNgt",
        "colab_type": "code",
        "outputId": "9c6af0b7-00d0-4f8e-83ab-ebd0218a4d4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(post_quan_tflite_file)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/tmp/tmpj97h_l1f.tflite\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dw0pNlGozoQV",
        "colab_type": "code",
        "outputId": "ade000f6-f2c9-4f18-c747-39d550d9a941",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print(y_test)\n",
        "print(type(x_test[0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1 1 ... 0 0 0]\n",
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zylF6-Optx7H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tflite 정확도 측정 함수\n",
        "import numpy as np\n",
        "\n",
        "def evaluate_model(interpreter):\n",
        "  input_index = interpreter.get_input_details()[0][\"index\"]\n",
        "  output_index = interpreter.get_output_details()[0][\"index\"]\n",
        "\n",
        "  # Run predictions on ever y image in the \"test\" dataset.\n",
        "  prediction_digits = []\n",
        "  for text in x_test:\n",
        "\n",
        "    # Pre-processing: add batch dimension and convert to float32 to match with\n",
        "    # the model's input data format.\n",
        "\n",
        "    text = np.expand_dims(text, axis=0).astype(np.float32)\n",
        "    interpreter.set_tensor(input_index, text)\n",
        "\n",
        "    # Run inference.\n",
        "    interpreter.invoke()\n",
        "\n",
        "    # Post-processing: remove batch dimension and find the digit with highest\n",
        "    # probability.\n",
        "    output = interpreter.tensor(output_index)\n",
        "    digit = np.argmax(output()[0])\n",
        "    prediction_digits.append(digit)\n",
        "\n",
        "  print('\\n')\n",
        "  # Compare prediction results with ground truth labels to calculate accuracy.\n",
        "  prediction_digits = np.array(prediction_digits)\n",
        "\n",
        "\n",
        "  accuracy = (prediction_digits == y_test).mean()\n",
        "  return accuracy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ofjo_kOwZvH4",
        "colab_type": "text"
      },
      "source": [
        "### TFLite 모델 실행\n",
        "\n",
        " TensorFlow Lite interpreter를 사용하여 TensorFlow Lite 모델을 실행하십시오."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDoiWC92OYP8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "interpreter_post_q = tf.lite.Interpreter(model_content=post_quan_tflite_model)\n",
        "interpreter_post_q.allocate_tensors()\n",
        "\n",
        "#test_post_q_accuracy = evaluate_model(interpreter_post_q)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DmHBhLWRvdWF",
        "colab_type": "code",
        "outputId": "30bb5212-f0df-4aee-b9a8-54b1ceeb05b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "source": [
        "test_post_q_accuracy = evaluate_model(interpreter_post_q)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "pd [0 0 0 ... 0 0 0]\n",
            "yy [0 1 1 ... 0 0 0]\n",
            "25000\n",
            "25000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsRXmf3i_pMl",
        "colab_type": "code",
        "outputId": "572176df-a7d2-452b-deda-189203aded0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('Post-Quant test accuracy:', test_post_q_accuracy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Post-Quant test accuracy: 0.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e10_WNxGOhr8",
        "colab_type": "text"
      },
      "source": [
        "## 4. pruned model and quantized model convert to TFLite"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Sm6AOx2RxIe",
        "colab_type": "text"
      },
      "source": [
        "### pruned model convert to tflite_model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a8cbYdRbOkwM",
        "colab_type": "code",
        "outputId": "14b3eb4c-de1a-4c89-cb79-f3c75e418757",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
        "pruned_tflite_model = converter.convert()\n",
        "\n",
        "_, pruned_tflite_file = tempfile.mkstemp('.tflite')\n",
        "\n",
        "with open(pruned_tflite_file, 'wb') as f:\n",
        "    f.write(pruned_tflite_model)\n",
        "\n",
        "print('Saved pruned TFLite model to:', pruned_tflite_file)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved pruned TFLite model to: /tmp/tmpd0vvjxc4.tflite\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ns5UYoHoSG-2",
        "colab_type": "text"
      },
      "source": [
        "### quantized model convert to tflite_model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0kLgsbASJ2E",
        "colab_type": "code",
        "outputId": "71ba214f-622d-4084-f34e-b14a655be0a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(q_aware_model)\n",
        "quantized_tflite_model = converter.convert()\n",
        "\n",
        "_, quantized_tflite_file = tempfile.mkstemp('.tflite')\n",
        "\n",
        "with open(quantized_tflite_file, 'wb') as f:\n",
        "    f.write(quantized_tflite_model)\n",
        "\n",
        "print('Saved quantized TFLite model to:', quantized_tflite_file)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved quantized TFLite model to: /tmp/tmpzd47hwkm.tflite\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0oHNl6voSNDI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "interpreter_p = tf.lite.Interpreter(model_content=pruned_tflite_model)\n",
        "interpreter_q = tf.lite.Interpreter(model_content=quantized_tflite_model)\n",
        "\n",
        "interpreter_p.allocate_tensors()\n",
        "interpreter_q.allocate_tensors()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dBjk42QLT7qO",
        "colab_type": "code",
        "outputId": "9a042691-f28d-4ed9-e4b4-d4e28b2a6924",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "test_accuracy_p = evaluate_model(interpreter_p)\n",
        "test_accuracy_q = evaluate_model(interpreter_q)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYjnO1ylSRCZ",
        "colab_type": "code",
        "outputId": "6bdd0c6e-4f36-44e8-87fd-57e2f167f908",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "print('Prun TFLite test_accuracy:', test_accuracy_p,\"\\n\")\n",
        "print('Quant TFLite test_accuracy:', test_accuracy_q,\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Prun TFLite test_accuracy: 0.5 \n",
            "\n",
            "Quant TFLite test_accuracy: 0.5 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VW1sh-dgSaA2",
        "colab_type": "text"
      },
      "source": [
        "# 5-1. baseline model with pruning and quantizing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qZ27Y8TTKfD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "q_aware_prun_model = quantize_model(model_for_export)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0u3igV4TKn0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "q_aware_prun_model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nj0D2ph4TKvw",
        "colab_type": "code",
        "outputId": "e1b82e9a-080c-45af-efa4-2b40280ae2bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        }
      },
      "source": [
        "q_aware_prun_model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "quantize_annotate_20 (Quanti (None, 100, 128)          2560000   \n",
            "_________________________________________________________________\n",
            "quantize_annotate_21 (Quanti (None, 128)               131584    \n",
            "_________________________________________________________________\n",
            "quantize_annotate_22 (Quanti (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "quantize_annotate_23 (Quanti (None, 1)                 129       \n",
            "_________________________________________________________________\n",
            "quantize_annotate_24 (Quanti (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 2,691,713\n",
            "Trainable params: 2,691,713\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONNGKFk5Ud37",
        "colab_type": "code",
        "outputId": "6dc59d4e-247b-4f27-f1da-7e911a51e9f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "print(\"Train...\")\n",
        "\n",
        "\n",
        "q_aware_prun_model.fit(x_train, y_train,\n",
        "                  batch_size=batch_size, epochs=3, validation_split=0.1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train...\n",
            "Epoch 1/3\n",
            "704/704 [==============================] - 22s 31ms/step - loss: nan - accuracy: 0.4986 - val_loss: nan - val_accuracy: 0.5124\n",
            "Epoch 2/3\n",
            "704/704 [==============================] - 21s 31ms/step - loss: nan - accuracy: 0.4986 - val_loss: nan - val_accuracy: 0.5124\n",
            "Epoch 3/3\n",
            "704/704 [==============================] - 22s 31ms/step - loss: nan - accuracy: 0.4986 - val_loss: nan - val_accuracy: 0.5124\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f218059f710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JAVQATLxTOws",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_images_subset = train_images[0:1000] # out of 60000\n",
        "# train_labels_subset = train_labels[0:1000]\n",
        "\n",
        "# q_aware_prun_model.fit(train_images_subset, train_labels_subset,\n",
        "#                   batch_size=128, epochs=4, validation_split=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_pUqGcjTQdR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_, q_aware_prun_model_accuracy =q_aware_prun_model.evaluate(x_test, y_test, verbose=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxgUzRCWTRsN",
        "colab_type": "code",
        "outputId": "18c2034e-010c-4ff8-be2a-b69eb188cece",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print('Pruned and quantized test_accuracy:', q_aware_prun_model_accuracy,\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pruned and quantized test_accuracy: 0.5 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnAl9OgwTX3c",
        "colab_type": "code",
        "outputId": "4bc24e50-8a53-4b42-dba6-7942d3e054b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "_, pruned_and_quantized_keras_file = tempfile.mkstemp('.h5')\n",
        "tf.keras.models.save_model(q_aware_prun_model, pruned_and_quantized_keras_file, include_optimizer=False)\n",
        "print('Saved pruned and quantized Keras model to:', pruned_and_quantized_keras_file)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved pruned and quantized Keras model to: /tmp/tmph6mdda6b.h5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jF-WbprOSaHB",
        "colab_type": "text"
      },
      "source": [
        "# 5-2. baseline model with pruning and post-quantizing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DRtipSFTdll",
        "colab_type": "code",
        "outputId": "4e810474-e637-44bd-bb89-03cda3ca47ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(model_for_export)\n",
        "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "post_quantized_and_pruned_tflite_model = converter.convert()\n",
        "\n",
        "_, post_quantized_and_pruned_tflite_file = tempfile.mkstemp('.tflite')\n",
        "\n",
        "with open(post_quantized_and_pruned_tflite_file, 'wb') as f:\n",
        "  f.write(post_quantized_and_pruned_tflite_model)\n",
        "\n",
        "print('Saved quantized and pruned TFLite model to:', post_quantized_and_pruned_tflite_file)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved quantized and pruned TFLite model to: /tmp/tmpwih04u28.tflite\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OrwLckK8TdvG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "interpreter_p_post_q = tf.lite.Interpreter(model_content=post_quantized_and_pruned_tflite_model)\n",
        "interpreter_p_post_q.allocate_tensors()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ga53lrb2Yhvk",
        "colab_type": "code",
        "outputId": "a97dc9aa-9305-4221-a7d6-049b66988819",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "test_accuracy_p_post_q = evaluate_model(interpreter_p_post_q)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjW7cCXdTitc",
        "colab_type": "code",
        "outputId": "4d6005e1-f044-495d-de4a-de2cf4b7b65a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print('Pruned and post-quantized test_accuracy:', test_accuracy_p_post_q,\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pruned and post-quantized test_accuracy: 0.5 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbXCAprMSaeD",
        "colab_type": "text"
      },
      "source": [
        "# 6. pruned and quantized model convert to TFLite"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbBLSEHnTmKL",
        "colab_type": "code",
        "outputId": "0282ffe6-0d88-4bdb-d56c-1bc6fead2d1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "converter = tf.lite.TFLiteConverter.from_keras_model(q_aware_prun_model)\n",
        "pruned_quantized_tflite_model = converter.convert()\n",
        "\n",
        "_, pruned_quantized_tflite_file = tempfile.mkstemp('.tflite')\n",
        "\n",
        "with open(pruned_quantized_tflite_file, 'wb') as f:\n",
        "    f.write(pruned_quantized_tflite_model)\n",
        "\n",
        "print('Saved pruned TFLite model to:', pruned_quantized_tflite_file)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saved pruned TFLite model to: /tmp/tmp_y8meadp.tflite\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sseB4jIfTnbJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "interpreter_p_q = tf.lite.Interpreter(model_content=pruned_quantized_tflite_model)\n",
        "interpreter_p_q.allocate_tensors()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUEDbhTBYmVm",
        "colab_type": "code",
        "outputId": "ceb7fd10-2b4d-4144-b13c-3348a005dd6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "test_accuracy_p_q = evaluate_model(interpreter_p_q)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EW0jIxQTnhr",
        "colab_type": "code",
        "outputId": "2c801904-e40e-4e7c-c519-6826bc5f909f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "print('Pruned and quantized TFLite test_accuracy:', test_accuracy_p_q,\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pruned and quantized TFLite test_accuracy: 0.5 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zDjl_1sSlj_",
        "colab_type": "text"
      },
      "source": [
        "# 결론(Result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hqDtni2SpYg",
        "colab_type": "text"
      },
      "source": [
        "## 모든 모델의 정확도"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vhEWsSLmSs-X",
        "colab_type": "code",
        "outputId": "d108ff13-b7a9-42e1-af46-52e8783e0e16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        }
      },
      "source": [
        "print('Baseline test accuracy:', baseline_model_accuracy,\"\\n\")\n",
        "print('Pruned test accuracy:', model_for_pruning_accuracy,\"\\n\")\n",
        "print('Quant test accuracy:', q_aware_model_accuracy,\"\\n\")\n",
        "print('Post-Quant test accuracy:', test_post_q_accuracy,\"\\n\")\n",
        "print('Prun TFLite test_accuracy:', test_accuracy_p,\"\\n\")\n",
        "print('Quant TFLite test_accuracy:', test_accuracy_q,\"\\n\")\n",
        "print('Pruned and quantized test_accuracy:', q_aware_prun_model_accuracy,\"\\n\")\n",
        "print('Pruned and post-quantized test_accuracy:', test_accuracy_p_post_q,\"\\n\")\n",
        "print('Pruned and post-quantized test_accuracy:', test_accuracy_p_q,\"\\n\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-84-b457c7315ae2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#print('Baseline test accuracy:', baseline_model_accuracy,\"\\n\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Pruned test accuracy:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_for_pruning_accuracy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Quant test accuracy:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_aware_model_accuracy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Post-Quant test accuracy:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_post_q_accuracy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Prun TFLite test_accuracy:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_accuracy_p\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'model_for_pruning_accuracy' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8soh7T8SwoI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "y = [baseline_model_accuracy, model_for_pruning_accuracy,\n",
        "     q_aware_model_accuracy, test_post_q_accuracy,\n",
        "     test_accuracy_p, test_accuracy_q,\n",
        "     q_aware_prun_model_accuracy, test_accuracy_p_post_q, test_accuracy_p_q]\n",
        "\n",
        "x = [\"base\", \"prun\", \"quan\", \"post\",\n",
        "     \"prun_tf\",\"quan_tf\", \"prun_quan\",\n",
        "     \"prun_post\", \"prun_quan_tf\"]\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.barh(x, y, color=\"skyblue\", height=0.6)\n",
        "plt.xlim(0.0,0.9)\n",
        "\n",
        "plt.yticks(x,fontsize=13)\n",
        "plt.title(\"Accuracy compare\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-Gnvon2SyTH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(8, 8))\n",
        "plt.barh(x, y, color=\"blue\")\n",
        "plt.xlim(0.83,0.868)\n",
        "\n",
        "plt.yticks(x,fontsize=13)\n",
        "plt.title(\"Accuracy compare\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "phSQt5oFSzSR",
        "colab_type": "text"
      },
      "source": [
        "## 모든 모델의 크기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfbskDeuS2VU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_gzipped_model_size(file):\n",
        "  # Returns size of gzipped model, in bytes.\n",
        "  import os\n",
        "  import zipfile\n",
        "\n",
        "  _, zipped_file = tempfile.mkstemp('.zip')\n",
        "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
        "    f.write(file)\n",
        "\n",
        "  return os.path.getsize(zipped_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2OSOnqkS3CN",
        "colab_type": "code",
        "outputId": "59de2ede-451d-42c2-db00-0e867651b073",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        }
      },
      "source": [
        "print(\"Size of gzipped baseline Keras model: %.2f bytes\\n\" % (get_gzipped_model_size(keras_file)))\n",
        "print(\"Size of gzipped pruned Keras model: %.2f bytes\\n\" % (get_gzipped_model_size(pruned_keras_file)))\n",
        "print(\"Size of gzipped quantizied Keras model: %.2f bytes\\n\" % (get_gzipped_model_size(quantized_keras_file)))\n",
        "print(\"Size of gzipped post-quantized model: %.2f bytes\\n\" % (get_gzipped_model_size(post_quan_tflite_file)))\n",
        "print(\"Size of gzipped pruned TFlite model: %.2f bytes\\n\" % (get_gzipped_model_size(pruned_tflite_file)))\n",
        "print(\"Size of gzipped quantized TFlite model: %.2f bytes\\n\" % (get_gzipped_model_size(quantized_tflite_file)))\n",
        "print(\"Size of gzipped pruned and quantized Keras model: %.2f bytes\\n\" % (get_gzipped_model_size(pruned_and_quantized_keras_file)))\n",
        "print(\"Size of gzipped pruned and post-quantized model: %.2f bytes\\n\" % (get_gzipped_model_size(post_quantized_and_pruned_tflite_file)))\n",
        "print(\"Size of gzipped pruned and quantized TFlite model: %.2f bytes\\n\" % (get_gzipped_model_size(pruned_quantized_tflite_file)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of gzipped baseline Keras model: 9966407.00 bytes\n",
            "\n",
            "Size of gzipped pruned Keras model: 4301966.00 bytes\n",
            "\n",
            "Size of gzipped quantizied Keras model: 10061041.00 bytes\n",
            "\n",
            "Size of gzipped post-quantized model: 144.00 bytes\n",
            "\n",
            "Size of gzipped pruned TFlite model: 10063918.00 bytes\n",
            "\n",
            "Size of gzipped quantized TFlite model: 10063936.00 bytes\n",
            "\n",
            "Size of gzipped pruned and quantized Keras model: 24956.00 bytes\n",
            "\n",
            "Size of gzipped pruned and post-quantized model: 6338.00 bytes\n",
            "\n",
            "Size of gzipped pruned and quantized TFlite model: 25982.00 bytes\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93kTKMz4S5YH",
        "colab_type": "code",
        "outputId": "4e678cfe-b26e-412f-b4f6-0c2f161f7577",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 512
        }
      },
      "source": [
        "y = [get_gzipped_model_size(keras_file),\n",
        "     get_gzipped_model_size(pruned_keras_file),\n",
        "     get_gzipped_model_size(quantized_keras_file),\n",
        "     get_gzipped_model_size(post_quan_tflite_file),\n",
        "     get_gzipped_model_size(pruned_tflite_file),\n",
        "     get_gzipped_model_size(quantized_tflite_file),\n",
        "     get_gzipped_model_size(pruned_and_quantized_keras_file),\n",
        "     get_gzipped_model_size(post_quantized_and_pruned_tflite_file),\n",
        "     get_gzipped_model_size(pruned_quantized_tflite_file)]\n",
        "\n",
        "\n",
        "x = [\"base\", \"prun\", \"quan\", \"post\",\n",
        "     \"prun_tf\",\"quan_tf\", \"prun_quan\",\n",
        "     \"prun_post\", \"prun_quan_tf\"]\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.barh(x, y, color=\"skyblue\", height=0.6)\n",
        "#plt.xlim(0.0,0.9)\n",
        "\n",
        "plt.yticks(x,fontsize=13)\n",
        "plt.title(\"Model Size compare\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RreHrTP9S6tM",
        "colab_type": "code",
        "outputId": "65c72e92-de56-4952-bd53-40b897a7dbfb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 294
        }
      },
      "source": [
        "y = [get_gzipped_model_size(pruned_keras_file),\n",
        "     get_gzipped_model_size(post_quan_tflite_file),\n",
        "     get_gzipped_model_size(pruned_tflite_file),\n",
        "     get_gzipped_model_size(quantized_tflite_file),\n",
        "     get_gzipped_model_size(post_quantized_and_pruned_tflite_file),\n",
        "     get_gzipped_model_size(pruned_quantized_tflite_file)]\n",
        "\n",
        "x = [\"prun\", \"post\",\n",
        "     \"prun_tf\",\"quan_tf\",\n",
        "     \"prun_post\", \"prun_quan_tf\"]\n",
        "\n",
        "plt.barh(x, y, color=\"blue\", height=0.6)\n",
        "#plt.xlim(0.0,0.9)\n",
        "\n",
        "plt.yticks(x,fontsize=13)\n",
        "plt.title(\"Model Size compare\")\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qO15I49US8RJ",
        "colab_type": "code",
        "outputId": "13c8b0b6-0737-4a2d-b5a7-4efe059433b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "y = [get_gzipped_model_size(post_quan_tflite_file),\n",
        "     get_gzipped_model_size(post_quantized_and_pruned_tflite_file)]\n",
        "\n",
        "x = [\"post\",\n",
        "     \"prun_post\"]\n",
        "\n",
        "plt.barh(x, y, color=\"red\", height=0.6)\n",
        "#plt.xlim(0.0,0.9)\n",
        "\n",
        "plt.yticks(x,fontsize=13)\n",
        "plt.title(\"Model Size compare\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_OKqF4PS9kv",
        "colab_type": "code",
        "outputId": "ede24b2d-709d-40e8-8e0d-f9daeb9b081b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "y = [get_gzipped_model_size(keras_file),\n",
        "     get_gzipped_model_size(quantized_keras_file),\n",
        "     get_gzipped_model_size(pruned_and_quantized_keras_file)]\n",
        "\n",
        "\n",
        "x = [\"base\", \"quan\", \"prun_quan\"]\n",
        "\n",
        "plt.barh(x, y, color=\"green\", height=0.6)\n",
        "plt.xlim(345000, 390000)\n",
        "\n",
        "plt.yticks(x,fontsize=13)\n",
        "plt.title(\"Model Size compare\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsNd8G9eTAq-",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "## accuracy and model size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhNGvseGTDJ_",
        "colab_type": "code",
        "outputId": "c35777a7-4acd-42ca-98da-f3e69d8b9471",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        }
      },
      "source": [
        "x = [baseline_model_accuracy, model_for_pruning_accuracy,\n",
        "     q_aware_model_accuracy, test_post_q_accuracy,\n",
        "     test_accuracy_p, test_accuracy_q,\n",
        "     q_aware_prun_model_accuracy, test_accuracy_p_post_q, test_accuracy_p_q]\n",
        "\n",
        "y = [get_gzipped_model_size(keras_file),\n",
        "     get_gzipped_model_size(pruned_keras_file),\n",
        "     get_gzipped_model_size(quantized_keras_file),\n",
        "     get_gzipped_model_size(post_quan_tflite_file),\n",
        "     get_gzipped_model_size(pruned_tflite_file),\n",
        "     get_gzipped_model_size(quantized_tflite_file),\n",
        "     get_gzipped_model_size(pruned_and_quantized_keras_file),\n",
        "     get_gzipped_model_size(post_quantized_and_pruned_tflite_file),\n",
        "     get_gzipped_model_size(pruned_quantized_tflite_file)]\n",
        "\n",
        "z = [\"base\", \"prun\", \"quan\", \"post\",\n",
        "     \"prun_tf\",\"quan_tf\", \"prun_quan\",\n",
        "     \"prun_post\", \"prun_quan_tf\"]\n",
        "\n",
        "c = ['b','g','r','c','yellow','m','k','orange',\"brown\"]\n",
        "d = [(10,10),(10,10),(10,-15),(10,10),(10,-15),(10,10),(10,10),(10,10),(10,10)]\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.scatter(x,y, color=c)\n",
        "\n",
        "for xs,ys in zip(x,y):\n",
        "    plt.annotate(z[x.index(xs)], (xs,ys), textcoords=\"offset points\",xytext=d[x.index(xs)],ha='right')\n",
        "    \n",
        "plt.ylabel('Model Size')\n",
        "plt.xlabel('Accuracy')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-93-e0c4955d36f8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m x = [baseline_model_accuracy, model_for_pruning_accuracy,\n\u001b[0m\u001b[1;32m      2\u001b[0m      \u001b[0mq_aware_model_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_post_q_accuracy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m      \u001b[0mtest_accuracy_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_accuracy_q\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m      q_aware_prun_model_accuracy, test_accuracy_p_post_q, test_accuracy_p_q]\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'baseline_model_accuracy' is not defined"
          ]
        }
      ]
    }
  ]
}